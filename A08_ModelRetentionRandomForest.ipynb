{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\", color_codes=True)\n",
    "\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "path='/Users/brianna/Documents/WL_DBdeets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a model and study the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This example is written for a generic classifier model (here, using a RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierVersion = 1\n",
    "features = ['NumberSignedUpFromCompany',\n",
    "          'MeetingsTotalWeek0_i','MeetingsTotalWeek1_0diff',\n",
    "          'PortionOfOrganizerWeek0','PortionOfOrganizerWeek1_0diff',\n",
    "          'AveNumAttendeesWeek0','AveNumAttendeesWeek1_0diff',\n",
    "          'completed_WL_actionWeek0','completed_WL_actionWeek1_0diff',\n",
    "          'EmailCorporateVsPrivate']\n",
    "\n",
    "prediction = 'RetentionStatus2Levels'\n",
    "#prediction = 'RetentionStatus'\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierVersion = 2\n",
    "features = ['MeetingsTotalWeek0_i','MeetingsTotalWeek1_0diff',\n",
    "            'PortionOfOrganizerWeek0_i','PortionOfOrganizerWeek1_0diff',\n",
    "            'AveNumAttendeesWeek0_i', 'AveNumAttendeesWeek1_0diff',\n",
    "            'NumberSignedUpFromCompany', \n",
    "            'sharedEmail',\n",
    "            'EmailCorporateVsPrivate']\n",
    "#prediction = 'WeeksVisitedOutOf12'\n",
    "prediction = 'RetentionStatus'\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierVersion = 3\n",
    "features = ['NumberSignedUpFromCompany', \n",
    "            'added_meetingWeek0','added_meetingWeek1_0diff',\n",
    "            'added_agenda_itemWeek0', 'added_agenda_itemWeek1_0diff',\n",
    "            'assigned_action_itemWeek0','assigned_action_itemWeek1_0diff']\n",
    "#prediction = 'WeeksVisitedOutOf12'\n",
    "prediction = 'RetentionStatus2Levels'\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierVersion = 4\n",
    "features = ['NumberSignedUpFromCompany',\n",
    "            'added_meetingWeek0','added_meetingWeek1_0diff',\n",
    "            'added_agenda_itemWeek0', 'added_agenda_itemWeek1_0diff']\n",
    "#prediction = 'WeeksVisitedOutOf12'\n",
    "prediction = 'RetentionStatus2Levels'\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifierVersion = 5\n",
    "features = ['NumberSignedUpFromCompany',\n",
    "            'added_meetingWeek0',\n",
    "            'added_agenda_itemWeek0']\n",
    "#prediction = 'WeeksVisitedOutOf12'\n",
    "prediction = 'RetentionStatus2Levels'\n",
    "classifier = RandomForestClassifier(n_estimators=1000, max_depth=20, min_samples_leaf=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#modelData = pd.read_csv(path+'06_DataFinal.csv')\n",
    "modelData = pd.read_csv(path+'06_DataFinal_withLogTransform.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove all rows with null values and see how many rows you have left.\n",
    "columns = features[:]\n",
    "columns.append(prediction)\n",
    "print('Columns remaining after rows with NA\\'s removed: '+str(len(modelData.dropna(subset=columns))))\n",
    "modelData=modelData.dropna(subset=columns)\n",
    "modelData[columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# classifierVersion = 2\n",
    "# surveyVersion = 1\n",
    "# features = [\"genderBoolean\", \"ageCategory\", \"medianHouseholdIncome\", \"fulltimeMedianIncome\"]\n",
    "# prediction = \"incomeCategory\"\n",
    "# classifier = RandomForestClassifier(n_estimators=500, max_depth=20, min_samples_leaf=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "versionLabel = \"version-{version:02d}\".format(version=classifierVersion)\n",
    "modelLabel = \"{model}\".format(model=classifier.__class__.__name__)\n",
    "predictionLabel = \"{prediction}\".format(prediction=prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test_size = 20% of data for testing\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(modelData[features], modelData[prediction].values, test_size=0.20)\n",
    "train = len(X_train)/float(len(modelData))\n",
    "test = len(X_test)/float(len(modelData))\n",
    "print \"The model data have been split into train data ({train:.2%}) and test data ({test:.2%})\".format(train=train, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier.verbose = True\n",
    "classifier.n_jobs = -1 # do as many jobs as there's room for on the computer\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions:\n",
    "Y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Probabilities:\n",
    "Y_proba = classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitions:\n",
    "\n",
    "- *True Positives* are those which are labeled ``1`` which are actually ``1``\n",
    "- *False Positives* are those which are labeled ``1`` which are actually ``0``\n",
    "- *True Negatives* are those which are labeled ``0`` which are actually ``0``\n",
    "- *False Negatives* are those which are labeled ``0`` which are actually ``1``\n",
    "\n",
    "\n",
    "Meaning of the different scores:\n",
    "\n",
    "$$ {\\rm accuracy} \\equiv \\frac{\\rm correct~labels}{\\rm total~samples} $$\n",
    "\n",
    "$$ {\\rm precision} \\equiv \\frac{\\rm true~positives}{\\rm true~positives + false~positives} $$\n",
    "\n",
    "$$ {\\rm recall} \\equiv \\frac{\\rm true~positives}{\\rm true~positives + false~negatives} $$\n",
    "\n",
    "$$ F_1 \\equiv 2 \\frac{\\rm precision \\cdot recall}{\\rm precision + recall} $$\n",
    "\n",
    "The **accuracy**, **precision**, **recall**, and **f1-score** all range from 0 to 1, with 1 being optimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_score = classifier.score(X_test, Y_test) # same as accuracy in random forest\n",
    "print classifier_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_accuracy_score = accuracy_score(Y_test, Y_pred)\n",
    "print classifier_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_precision_score = precision_score(Y_test, Y_pred, average=\"weighted\")\n",
    "print classifier_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_recall_score = recall_score(Y_test, Y_pred, average=\"weighted\")\n",
    "print classifier_recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier_f1_score = f1_score(Y_test, Y_pred, average=\"weighted\")\n",
    "print classifier_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the labels used for the classification (without escaping dollar signs):\n",
    "# classifierLabels = {}\n",
    "# for (key, value) in incomeRanges.items():\n",
    "#     classifierLabels[key] = r\"${low:,}-${high:,}\".format(low=value[0], high=value[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#classifier_classification_report = classification_report(Y_test, Y_pred, target_names=classifierLabels.values())\n",
    "classifier_classification_report = classification_report(Y_test, Y_pred)\n",
    "print(classifier_classification_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns = ['feature','importance'], index=range(len(features)))\n",
    "if isinstance(classifier, RandomForestClassifier):\n",
    "    i=0\n",
    "    for (feature, importance) in zip(features, classifier.feature_importances_):\n",
    "        print feature, importance\n",
    "        df.feature[i] = feature\n",
    "        df.importance[i] = importance\n",
    "        i+=1\n",
    "\n",
    "dfsort = df.sort(columns = ['importance'], ascending = False)\n",
    "dfsort.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.bar(dfsort.feature, \n",
    "#         dfsort.importance,\n",
    "#         color='b',\n",
    "#         abel='Feature Importance')\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "ax = sns.barplot(x='feature', y='importance', data=dfsort);\n",
    "ax.set(xlabel='Feature', ylabel='Importance of each Feature')\n",
    "\n",
    "for item in ax.get_xticklabels():\n",
    "    item.set_rotation(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to plot the confusion matrix:\n",
    "def plotFeatureImportance(ax, cm, title='Feature importance', cmap=plt.cm.Blues):\n",
    "    # Plot the confusion matrix:\n",
    "    image = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    # Plot the label on the ticks:\n",
    "    tick_marks = np.arange(len(classifierLabels))\n",
    "    ax.set_xticks(tick_marks, list(classifierLabels.values()))\n",
    "    ax.set_yticks(tick_marks, list(classifierLabels.values()))\n",
    "    locations = ax.set_xticks(tick_marks)\n",
    "    labels = ax.set_xticklabels(list(classifierLabels.values()))\n",
    "    for label in labels:\n",
    "        label.update({'rotation':90})\n",
    "    locations = ax.set_yticks(tick_marks)\n",
    "    labels = ax.set_yticklabels(list(classifierLabels.values()))\n",
    "    # Add colorbars:\n",
    "    divider = make_axes_locatable(ax)\n",
    "    colorbar_ax = divider.append_axes(\"right\", size=\"10%\", pad=0.05)\n",
    "    colorbar = ax.figure.colorbar(image, cax=colorbar_ax)\n",
    "\n",
    "# Create the figure:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 15))\n",
    "#fig.suptitle(\"Model: {version}, {model}\".format(version=versionLabel, model=modelLabel), fontsize=12)\n",
    "for ax in axes:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "plotFeatureImportance(axes[0], cm)\n",
    "\n",
    "# Save the figure:\n",
    "prefix = \"-{version}\".format(version=versionLabel)\n",
    "fileName = \"confusion-matrices\" + prefix + \".pdf\"\n",
    "outputDirectory = path+\"model_images\"\n",
    "outputPath = os.path.join(outputDirectory, fileName)\n",
    "fig.savefig(outputPath, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save information into a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prefix = \"-{version}\".format(version=versionLabel)\n",
    "fileName = \"model\" + prefix + \".txt\"\n",
    "outputDirectory = path+\"model_images\"\n",
    "outputPath = os.path.join(outputDirectory, fileName)\n",
    "with open(outputPath, \"w\") as f:\n",
    "    f.write(\"Version: {version}\\n\".format(version=versionLabel))\n",
    "    f.write(\"Model:   {model}\\n\".format(model=modelLabel))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Classifier: {score:.2f}\\n\".format(score=classifier_score))\n",
    "    f.write(\"Accuracy:   {score:.2f}\\n\".format(score=classifier_accuracy_score))\n",
    "    f.write(\"Precision:  {score:.2f}\\n\".format(score=classifier_precision_score))\n",
    "    f.write(\"Recall:     {score:.2f}\\n\".format(score=classifier_recall_score))\n",
    "    f.write(\"F1:         {score:.2f}\\n\".format(score=classifier_f1_score))\n",
    "    f.write(\"\\n\")\n",
    "    f.write(\"Score {score}\\n\".format(score=classifier_classification_report))\n",
    "    f.write(\"\\n\")\n",
    "    if isinstance(classifier, RandomForestClassifier):\n",
    "        f.write(\"Feature importance\\n\")\n",
    "        for (feature, importance) in zip(features, classifier.feature_importances_):\n",
    "            f.write(\"{feature}\\t {importance:.2f}\\n\".format(feature=feature, importance=importance))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the labels used for the classification (escaping the dollar signs):\n",
    "classifierLabels = {}\n",
    "if prediction == \"RetentionStatus\":\n",
    "    for (key, value) in incomeRanges.items():\n",
    "        classifierLabels[key] = r\"\\${low:,}-\\${high:,}\".format(low=value[0], high=value[2])\n",
    "# elif prediction == \"binnedIncomeCategory\":\n",
    "#     for (key, value) in binnedIncomeRanges.items():\n",
    "#         classifierLabels[key] = r\"\\${low:,}-\\${high:,}\".format(low=value[0], high=value[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(Y_test, Y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "print('Confusion matrix, without normalization')\n",
    "print(cm)\n",
    "\n",
    "# Normalize the confusion matrix by row (i.e by the number of samples in each class)\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print('Normalized confusion matrix')\n",
    "print(cm_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to plot the confusion matrix:\n",
    "def plot_confusion_matrix(ax, cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    # Plot the confusion matrix:\n",
    "    image = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    # Plot the label on the ticks:\n",
    "    tick_marks = np.arange(len(classifierLabels))\n",
    "    ax.set_xticks(tick_marks, list(classifierLabels.values()))\n",
    "    ax.set_yticks(tick_marks, list(classifierLabels.values()))\n",
    "    locations = ax.set_xticks(tick_marks)\n",
    "    labels = ax.set_xticklabels(list(classifierLabels.values()))\n",
    "    for label in labels:\n",
    "        label.update({'rotation':90})\n",
    "    locations = ax.set_yticks(tick_marks)\n",
    "    labels = ax.set_yticklabels(list(classifierLabels.values()))\n",
    "    # Add colorbars:\n",
    "    divider = make_axes_locatable(ax)\n",
    "    colorbar_ax = divider.append_axes(\"right\", size=\"10%\", pad=0.05)\n",
    "    colorbar = ax.figure.colorbar(image, cax=colorbar_ax)\n",
    "\n",
    "# Create the figure:\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "fig.suptitle(\"Model: {version}, {model}\".format(version=versionLabel, model=modelLabel), fontsize=12)\n",
    "for ax in axes:\n",
    "    ax.set_aspect(1)\n",
    "\n",
    "plot_confusion_matrix(axes[0], cm)\n",
    "plot_confusion_matrix(axes[1], cm_normalized, title='Normalized confusion matrix')\n",
    "\n",
    "# Save the figure:\n",
    "prefix = \"-{version}\".format(version=versionLabel)\n",
    "fileName = \"confusion-matrices\" + prefix + \".pdf\"\n",
    "outputDirectory = path+\"model_images\"\n",
    "outputPath = os.path.join(outputDirectory, fileName)\n",
    "fig.savefig(outputPath, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
