{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "#from datetime import date, datetime, timedelta # to manipulate dates\n",
    "\n",
    "from pylab import savefig\n",
    "from __future__ import division\n",
    "import statistics\n",
    "from datetime import datetime\n",
    "% matplotlib inline\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_context(context='notebook', font_scale=1.5, rc=None)\n",
    "\n",
    "path='/Users/brianna/Documents/WL_DBdeets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def makeDFsubset(df, varListOneNumber, varListByWeek):\n",
    "    # Not Including: \n",
    "    # added_noteWeek0 - stopped being collected in September\n",
    "    # viewed_onboarding__tour_4_pageWeek - only collected starting in September\n",
    "    \n",
    "    # Expand varListByWeek to grab both Week0 and Week1 variables\n",
    "    varListByWeekExpanded = []\n",
    "    for v in varListByWeek:\n",
    "        varListByWeekExpanded.append(v+'Week0')\n",
    "        varListByWeekExpanded.append(v+'Week1')\n",
    "     \n",
    "    # Take just the variables that you want to look at later.\n",
    "    df = df.loc[:,varListOneNumber + varListByWeekExpanded]\n",
    "    \n",
    "    # Make this EmailCorporateVsPrivate variable, which is .5 for corporate\n",
    "    # and -.5 for school or personal email accounts.\n",
    "    df['EmailCorporateVsPrivate']=0\n",
    "    corpEmail = df.emailDomain == 'company'\n",
    "    personalEmail = df['emailDomain'] == 'personal'\n",
    "    schoolEmail = df['emailDomain'] == 'school'\n",
    "    df.loc[corpEmail,'EmailCorporateVsPrivate'] = .5\n",
    "    df.loc[personalEmail,'EmailCorporateVsPrivate'] = -.5\n",
    "    df.loc[schoolEmail,'EmailCorporateVsPrivate'] = -.5\n",
    "    \n",
    "    # Add another variable called completed_WL_action which sums over all\n",
    "    # WL actions I collected.\n",
    "    df['completed_WL_actionWeek0'] = df.added_meetingWeek0 + df.added_agenda_itemWeek0 + df.assigned_action_itemWeek0\n",
    "    df['completed_WL_actionWeek1'] = df.added_meetingWeek1 + df.added_agenda_itemWeek1 + df.assigned_action_itemWeek1\n",
    "    varListByWeek.append('completed_WL_action')\n",
    "\n",
    "    # Make a dummy variable of 1's in case we need it later when we try to sum things.\n",
    "    df['dummy'] = 1\n",
    "    \n",
    "    return df, varListByWeek, varListByWeekExpanded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the difference in events from week X to week Y, then drop the variables\n",
    "# for the individual weeks 0 and 1 from the dataframe.\n",
    "def calculateWeekX_YDiff(df, varListByWeek, X, Y):\n",
    "    varListByWeekNew = []\n",
    "    #varListDrop = []\n",
    "    for v in varListByWeek:\n",
    "        df[v+str(Y)+'plus'+str(X)]=(df[v+'Week'+str(Y)]+df[v+'Week'+str(X)])/2\n",
    "        df[v+str(Y)+'minus'+str(X)]=df[v+'Week'+str(Y)]-df[v+'Week'+str(X)] \n",
    "        varListByWeekNew.append(v+str(Y)+'plus'+str(X))\n",
    "        varListByWeekNew.append(v+str(Y)+'minus'+str(X))\n",
    "        #varListDrop.append(v+'Week'+str(X))\n",
    "        #varListDrop.append(v+'Week'+str(Y))\n",
    "        \n",
    "    #df = df.drop(varListDrop, axis=1)\n",
    "    # Add the newly calculated variables to the \n",
    "    return df, varListByWeekNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pullInOutliers(df, varListContinuous, numStdDev):\n",
    "    for v in varListContinuous:\n",
    "        #print(v)\n",
    "        varUpperLimit = np.mean(df[v]) + numStdDev*np.std(df[v])\n",
    "        varLowerLimit = np.mean(df[v]) - numStdDev*np.std(df[v])\n",
    "        \n",
    "        #(df[v] > varMean - 5*varStdDev) and \n",
    "        #print(str(varUpperLimit)+', '+str(varLowerLimit))\n",
    "        #df.loc[df[v] > varUpperLimit, v] = varUpperLimit\n",
    "        #df.loc[df[v] < varLowerLimit, v] = varLowerLimit\n",
    "        df.loc[df[v] > varUpperLimit, v] = None\n",
    "        df.loc[df[v] < varLowerLimit, v] = None\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def imputeVars(df, varListContinuous, pctCutOff):    \n",
    "    varListContinuousNew = varListContinuous[:]\n",
    "    for v in varListContinuous:\n",
    "        totMissing = len(df.loc[df[v].isnull(),v])\n",
    "        totUser = len(df[v])\n",
    "        pctMissing = totMissing/totUser\n",
    "        print(v+': '+str(pctMissing))\n",
    "        # If less than X% of data (pctCutOff) is missing, replace missing data with the median of the data\n",
    "        # Append a '_i' on the end of the variable so you know it's been imputed.\n",
    "        if pctMissing < pctCutOff:\n",
    "            df[v+'_i']=df[v][:]\n",
    "            #df.loc[df[v+'_i'].isnull(),v+'_i']=np.mean(df[v])\n",
    "            df.loc[df[v+'_i'].isnull(),v+'_i']=statistics.median(df[v])\n",
    "            varListContinuousNew.append(v+'_i')\n",
    "            \n",
    "    return df, varListContinuousNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logTransformVars(df, varListContinuous):    \n",
    "    logVars = []\n",
    "    for v in varListContinuous:\n",
    "        if '1minus0' not in v:\n",
    "            df[v+'_log']=df[v].apply(lambda x : math.log(x+1.0))\n",
    "            #df[v+'_log']=math.log(df[v][:]+1.0)\n",
    "            logVars.append(v+'_log')\n",
    "            #print(v+'_log')\n",
    "    \n",
    "    varListContinuous += logVars\n",
    "    \n",
    "    return df, varListContinuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotCorrMatrix(df, varList, nameAppend):\n",
    "    \n",
    "    df=df.loc[:,varList]\n",
    "    sns.set(style=\"white\")\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "    #print(corr)\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(20, 18))\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3,\n",
    "                square=True, xticklabels=True, yticklabels=True,\n",
    "                linewidths=.5, cbar_kws={\"shrink\": .5}, ax=ax)\n",
    "    \n",
    "    savefig(path+'images/correlationMatrix'+nameAppend+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plotVarHist(df, variableName):\n",
    " \n",
    "    plt.figure(figsize=(20,10))\n",
    "    #df[variableName].hist(bins = len(df[variableName].unique()))\n",
    "    df[variableName].hist()\n",
    "\n",
    "    plt.xlabel(variableName, size=20)\n",
    "    plt.ylabel('Count', size = 20)\n",
    "    plt.savefig(path+'images/'+variableName+'Histogram.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plotVarByWeek(df, variableName):\n",
    "    plt.figure(figsize=(15,15))\n",
    "    sums = df.groupby('registrationWeek')[variableName].sum()\n",
    "    #print(sums.index[:5])\n",
    "    #print(sums[:5])\n",
    "    #plt.bar(df['registrationWeek'], df[variableName])\n",
    "    \n",
    "    sns.set()\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    ax = sns.barplot(x=sums.index, y=sums, label = 'medium', color='blue')\n",
    "    ax.set(xlabel='Week', ylabel='Instances of '+variableName)\n",
    "    \n",
    "    for item in ax.get_xticklabels():\n",
    "        item.set_rotation(45)\n",
    "        \n",
    "    #ax.savefig(path+variableName+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make List of variables and take a subset of df with just these variables.\n",
    "varListCategorical = ['user_id', \n",
    "                      'registrationWeek',\n",
    "                      'sharedEmail',\n",
    "                      'emailDomain']\n",
    "varListOther = ['NumberSignedUpFromCompany']\n",
    "\n",
    "varListByWeek =  ['MeetingsTotal',\n",
    "                  'organizerTotal',\n",
    "                  'PortionOfOrganizer',\n",
    "                  'num_attendees',\n",
    "                  'AveNumAttendees', \n",
    "                  'added_meeting',\n",
    "                  'added_agenda_item',\n",
    "                  'assigned_action_item']\n",
    "\n",
    "varListRetention = ['RetentionStatus2Levels',\n",
    "                    'RetentionStatus4Levels',\n",
    "                    'WeeksVisitedOutOf12']\n",
    "\n",
    "varListOneNumber = varListCategorical + varListOther + varListRetention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in the dataframe with all of the variables of interest.\n",
    "df = pd.read_csv(path+'05_RetentionMeetingsBehaviorFull.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, remove any data before July 1 (or June 28, since that's the nearest cohort).  \n",
    "# Val isn't sure if we can trust anything before that because they were still figuring \n",
    "# out the data collection.\n",
    "x = df[(df.registrationWeek !='2015-05-24') &\n",
    "       (df.registrationWeek !='2015-05-31') &\n",
    "       (df.registrationWeek !='2015-06-07') &\n",
    "       (df.registrationWeek !='2015-06-14') &\n",
    "       (df.registrationWeek !='2015-06-21')]\n",
    "\n",
    "print(len(x))\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now take a subset of the dataframe with just the variables that we're interested in.\n",
    "df, varListByWeek, varListByWeekExpanded = makeDFsubset(df, varListOneNumber, varListByWeek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "varListByWeek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the events velocity (difference in events from Week0 to Week1)\n",
    "df, varListByWeek = calculateWeekX_YDiff(df, varListByWeek, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If there are extreme values (ie. greater than 4 sd from the mean), pull them\n",
    "# in to 4 sd from the mean.\n",
    "varListContinuous = varListOther + varListByWeek + varListByWeekExpanded\n",
    "df = pullInOutliers(df, varListContinuous, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# If less than 31% of data is missing, make a variable with imputations on missing values.\n",
    "df, varListContinuous = imputeVars(df, varListContinuous, .31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make log-transformed variables of the continuous variables since they're all super skewed.\n",
    "df, varListContinuous = logTransformVars(df, varListContinuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get a list of the variables that were both imputed and log-transformed.\n",
    "varsOfInterest = []\n",
    "for v in varListContinuous:\n",
    "    if 'Week0_i_log' in v:\n",
    "        varsOfInterest.append(v)\n",
    "print(varsOfInterest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot the correlation matrix (for all variables, then just our nice imputed, log-transformed ones)\n",
    "plotCorrMatrix(df, df.columns, 'allVars')\n",
    "plotCorrMatrix(df, varListRetention+varsOfInterest, 'varsOfInterestImputedLogTransformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in varListContinuous:\n",
    "    plotVarHist(df,v)\n",
    "    #plotVarByWeek(df, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in varListContinuous:\n",
    "    plotVarByWeek(df, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(path+'06_DataFinal3SDRemoved.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
